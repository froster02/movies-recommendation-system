{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCUMENT DEFINATION OF fit_transform\n",
    "# source : https://github.com/scikit-learn/scikit-learn/blob/15a949460/sklearn/feature_extraction/text.py#L1172\n",
    "\n",
    "# def fit_transform(self, raw_documents, y=None):\n",
    "#         \"\"\"Learn the vocabulary dictionary and return document-term matrix.\n",
    "#         This is equivalent to fit followed by transform, but more efficiently\n",
    "#         implemented.\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         raw_documents : iterable\n",
    "#             An iterable which yields either str, unicode or file objects.\n",
    "#         Returns\n",
    "#         -------\n",
    "#         X : array of shape (n_samples, n_features)\n",
    "#             Document-term matrix.\n",
    "#         \"\"\"\n",
    "#         # We intentionally don't call the transform method to make\n",
    "#         # fit_transform overridable without unwanted side effects in\n",
    "#         # TfidfVectorizer.\n",
    "#         if isinstance(raw_documents, str):\n",
    "#             raise ValueError(\n",
    "#                 \"Iterable over raw text documents expected, \"\n",
    "#                 \"string object received.\")\n",
    "\n",
    "#         self._validate_params()\n",
    "#         self._validate_vocabulary()\n",
    "#         max_df = self.max_df\n",
    "#         min_df = self.min_df\n",
    "#         max_features = self.max_features\n",
    "\n",
    "#         vocabulary, X = self._count_vocab(raw_documents,\n",
    "#                                           self.fixed_vocabulary_)\n",
    "\n",
    "#         if self.binary:\n",
    "#             X.data.fill(1)\n",
    "\n",
    "#         if not self.fixed_vocabulary_:\n",
    "#             n_doc = X.shape[0]\n",
    "#             max_doc_count = (max_df\n",
    "#                              if isinstance(max_df, numbers.Integral)\n",
    "#                              else max_df * n_doc)\n",
    "#             min_doc_count = (min_df\n",
    "#                              if isinstance(min_df, numbers.Integral)\n",
    "#                              else min_df * n_doc)\n",
    "#             if max_doc_count < min_doc_count:\n",
    "#                 raise ValueError(\n",
    "#                     \"max_df corresponds to < documents than min_df\")\n",
    "#             if max_features is not None:\n",
    "#                 X = self._sort_features(X, vocabulary)\n",
    "#             X, self.stop_words_ = self._limit_features(X, vocabulary,\n",
    "#                                                        max_doc_count,\n",
    "#                                                        min_doc_count,\n",
    "#                                                        max_features)\n",
    "#             if max_features is None:\n",
    "#                 X = self._sort_features(X, vocabulary)\n",
    "#             self.vocabulary_ = vocabulary\n",
    "\n",
    "#         return X"
   ]
  }
 ]
}